\chapter{Automated Distribution of Quantum Algorithms}
\label{chap:Project}

\section{Implementing non-local CNOT gates}
\label{NonLocalGates}

In \S\ref{IntroDistributing}, we explained the proposal by~\citet{NonLocalCNOT} of how to implement a non-local gate. We will now extend their results.

In the original work, in order to implement multiple non-local gates using a single ebit, there must not be any operation on the control qubit between the non-local gates. However, many of the 1-qubit gates from the Clifford+T set commute with the CNOT gate. This means that, if there are operations in between CNOTs, we may transform the circuit to an equivalent version where the CNOT gates are brought together. And although some of the gates do not commute with CNOT, in some cases they can still be interchanged with it if an additional 1-qubit gate is added. All of the relevant circuit transformations are shown in Figure~\ref{fig:pullRules}. These can be checked by calculating the corresponding matrices of both sides and verifying they match.

\input{Figures/PullRules}

The second improvement comes by realising that the method used to implement multiple CNOT gates controlled by the same wire (explained in \S\ref{IntroDistributing}) can also be applied if multiple CNOT have a common target qubit instead. We will refer to the former method as the \textit{remote-control} method and \textit{remote-target} for the latter. The derivation of the remote-target method is shown in Figure~\ref{fig:CNOTtargetProof}, which uses some of the properties listed in \S\ref{Models}. The main difference is that the CNOT itself is now applied in the control QPU instead of the target, so the cat-entangler and cat-disentangler must change accordingly.

\input{Figures/TargetProof}

\section{Finding an efficient distribution}
\label{EfficientDistrib}

In this section we explain how we search for a suitable distribution of the circuit. But first, we establish what we mean by a distributed circuit to be efficient. This is based on what was discussed in \S\ref{DQC_Architecture} to be the bottle-necks of a distributed quantum architecture. A distributed circuit is efficient when there is:

\begin{itemize}
  \item \textit{Minimal amount of quantum communication} between the QPUs, meaning it requires as little number of ebits as possible. In comparison, message passing of classical bits is considered negligible and it is not taken into account.
  \item \textit{Load-balance across the QPUs}, up to a tolerance margin. Our notion of load-balance is that the different QPUs have a similar number of qubits assigned to them. A uniform depth of the local circuits (i.e.\ length of the circuits) would be desirable. However, the distributed circuit depth is inherited from the original circuit, as none of our distribution techniques change the depth in a significant way. Hence, we will not take circuit depth into account, and instead assume that already known methods for depth reduction, such as the one described by~\citet{DepthReduction}, have already been applied on the input circuit, and may be applied again to each QPU's local circuit. As circuit depth is not something we aim to optimise, we consider the cost of local gates negligible.
\end{itemize}

The problem at hand is similar to the  \textit{(\(k,\varepsilon\))-graph partitioning} problem. In it, a graph partition in \(k\) subgraphs has to be found, minimising the number of \textit{cut edges}: edges that have their incident vertices in different subgraphs. Additionally, the resulting partition must satisfy that the number of vertices in each subgraph is less than \((1 \pm \varepsilon)\frac{N}{k}\), where \(N\) is the total number of vertices in the graph. In Table~\ref{tab:matching} we list the correspondences between these two problems.

\begin{table}
\caption{Correspondence between the graph partitioning problem and the efficient distribution of quantum circuits.}
\label{tab:matching}
\centering
\begin{tabular}{|c|c|}
\hline
\textit{Graph partitioning} & \textit{Efficient distribution} \\
\hline
Vertices & Circuit wires \\
Edges & CNOT gates \\
Partitioned graph & Distributed circuit \\
Subgraph & QPU \\
Min. cut edges & Min. non-local gates \\
Uniform subgraph size & Load-balance \\
\hline
\end{tabular}
\end{table}

But there is a caveat. If we use graph partitioning naively, we will not be exploiting the fact that multiple CNOT gates may be implemented using a single ebit. In what follows, we will explain how to make use of \textit{hypergraph} partitioning, instead of simple graph partitioning, to account for this aspect. A more detailed review of the hypergraph partition problem is given in Appendix~\ref{chap:HypPart}, here we summarise the key concepts:

\begin{itemize}
  \item Hypergraphs extend graphs to accommodate edges that may have more than two incident vertices. More formally, a hypergraph is a pair \((V,H)\), where \(V\) is the set of vertices and \(H \subseteq 2^V\) is the collection\footnote{\, We will allow multiple hyperedges connecting the same vertices, in the same way as multigraphs allow multiple edges across any pair of edges.} of hyperedges. Each hyperedge is represented as the subset of vertices from \(V\) it connects. We will not consider any notion of directionality.
  \item Hypergraph partitioning follows the same premise as graph partitioning. The user provides a hypergraph and two parameters \((k,\varepsilon)\), which have the exact same meaning as before. What the problem now attempts to minimise is a metric known as \(\lambda\!-\!1\), which is defined as follows: Given a partition of the hypergraph, the function \(\lambda\colon\, H \to \mathbb{N}\) pairs each hyperedge with the number of different \textit{blocks}\footnote{\, The term \textit{block} is often used to refer to each of the sub-hypergraphs that comprise the hypergraph partition. It is the term we will use throughout this thesis.} its vertices are in. Then, \(\lambda\!-\!1 = \sum_{h \in H} \lambda(h) - 1\) provides a measure of not only how many hyperedges are cut but also how many blocks are they connecting\footnote{\, Simply minimising the number of cut hyperedges is also an often used approach, but it is not as useful for our problem.}.
\end{itemize}

In the following subsections, we explain how hypergraph partitioning can be used to find the best distribution of a circuit. First, we only use the implementation of non-local gates described by~\citet{NonLocalCNOT} reviewed in \S\ref{IntroDistributing}. Later on, we extend the algorithm to include the improvements we have proposed in \S\ref{NonLocalGates}.

\subsection{Vanilla algorithm}
\label{Vanilla}

The key challenge is how to use hyperedges to represent a collection of CNOT gates that, in case of being non-local, they could all be implemented using a single ebit. In this first version of the algorithm, we will group CNOTs together only if they have a common control wire and there are no other gates in between their connections to that wire. We will create \textit{a single hyperedge} for every such a collection of CNOT gates. The hyperedge's vertices will correspond to the controlling wire and each of the different wires the CNOT gates target. Algorithm~\ref{code:buildHypVanilla} receives a circuit as input and builds its hypergraph in that way. 

\begin{algorithm}[caption={Builds the hypergraph of a given circuit. \(H\) may contain multiple hyperedges connecting the same vertices. This algorithm runs in time \(O(g)\), where \(g\) is the number of gates in the input circuit.}, label={code:buildHypVanilla}]
input: circuit
output: (V,H)
begin
  V $\gets$ $\varnothing$
  H $\gets$ $\varnothing$
  hedge $\gets$ $\varnothing$
  foreach wire in circuit do
    V $\gets$ V $\cup$ {wire}
    H $\gets$ H $+$ {hedge}
    hedge $\gets$ {wire}
    foreach gate in wire do
      if gate == CNOT and $controlOf$(gate) == wire then
        hedge $\gets$ hedge $\cup$ {$targetOf$(gate)}
      else
        H $\gets$ H $+$ {hedge}
        hedge $\gets$ {wire}
end
\end{algorithm}

%Besides, it may be surprising that our hyperedges do not indicate which of the vertices is the control wire. That information is irrelevant at the partitioning level: each time a hyperedge is cut, we will require an ebit to implement the non-local gates, no matter which QPU the control wire is assigned to. Such information is only relevant when transforming the circuit into its distributed form, which is the next step of our algorithm. 

We then solve the hypergraph partitioning problem (see Appendix~\ref{chap:HypPart}) on the resulting hypergraph. Once an efficient partition of the hypergraph is obtained, we map the partition back to the circuit, distributing it. The way the vertices are assigned in the blocks determines how the corresponding wires are allocated to the different QPUs. The \(\lambda-1\) metric of the partition indicates the number of ebits that will be necessary to implement all the non-local CNOT gates. Hence, the problem of finding the optimal partition for a hypergraph built by Algorithm~\ref{code:buildHypVanilla}, and the problem of efficiently\footnote{Where efficiency is assessed as discussed in the beginning of this section.} distributing a circuit are the equivalent -- given any solution to one of them, we can compute a solution for the other. We formalise this result in the following theorem:

\begin{theorem} Given any circuit \(\mathcal{C}\), and its hypergraph \(\mathcal{H}\) generated by Algorithm~\ref{code:buildHypVanilla}, there is a bijection between partitions of \(\mathcal{H}\) with \(\lambda_c\) cuts and vanilla~\footnote{Meaning that non-local CNOT gates may only be implemented using the remote-control method from Figure~\ref{fig:nonlocalCNOTs}.} distributions of \(\mathcal{C}\) using \(\lambda_e\) ebits.
\label{thm:vanilla}
\end{theorem} \begin{proof}
We define this bijection inductively. First, we provide the bijection between the \textit{trivial configurations}:
\begin{itemize}
  \item The partition of \(\mathcal{H}\) where all vertices are in the same block corresponds one-to-one to 
  \item the \(\mathcal{C}\) being executed in a single QPU.
\end{itemize}

Then, we define a \textit{primitive transformation} for both problems, which allows us to move vertices/wires around. To do so, we use the one-to-one correspondence between vertices and wires that Algorithm~\ref{code:buildHypVanilla} imposed. We additionally require to have an indexed set of hypergraph blocks and QPUs.
\begin{itemize}
  \item Given a partition of \(\mathcal{H}\), \(\varphi\), moving vertex \(x\) from block \(i\) to block \(j\) corresponds one-to-one to
  \item picking wire \(x\) -- which is guaranteed to be in QPU \(i\) -- and allocating it in QPU \(j\).
\end{itemize}

Using this primitive, any partition/distribution can be reached, so we indeed have a bijection. Notice that wire \(x\) was guaranteed to be in QPU \(i\) thanks to our inductive definition of the bijection itself. It remains to proof that the given bijection preserves the number of cuts/ebits, which we will refer to as \(\lambda_c\) and \(\lambda_e\) respectively. We give a proof by induction on the sequence of primitives applied to reach an arbitrary configuration \(\varphi\) from the trivial configuration. 
\begin{itemize}
  \item The \textit{trivial case} of both problems have \(\lambda_c = \lambda_e = 0\).
  \item Given a sequence of \(n+1\) primitives, we assume that \(\lambda_c = \lambda_e\) by the time the \(n\)-th primitive was applied (our induction hypothesis). Then, reallocating vertex \(x\) from block \(i\) to block \(j\), as determined by the \((n+1)\)-th primitive, may:
    \begin{enumerate}
    \renewcommand{\theenumi}{\alph{enumi})}
      \item \textit{Increase} \(\lambda_c\). \(\lambda_c\) increases by one iff a new cut is added to an arbitrary hyperedge \(h\). This happens iff the block/QPU \(j\) did not already contain a vertex/wire from \(h\). In that case, in order to implement the isolated non-local CNOT, it will be necessary and sufficient to create an extra ebit, increasing \(\lambda_e\) by one. Therefore, \(\lambda_e\) will increase iff \(\lambda_c\) does so, both by the same amount.
      \item \textit{Decrease} \(\lambda_c\). In the same spirit, \(\lambda_c\) decreases by one iff a previously isolated vertex/wire is allocated where some fellow vertices/wires are. One less ebit will be required when and only when this happens. Therefore, \(\lambda_e\) will decrease iff \(\lambda_c\) does so, both by the same amount.
    \end{enumerate}
\end{itemize}

Therefore, starting from \(\lambda_c = \lambda_e = 0\) and applying the whole sequence of primitives one by one will maintain \(\lambda_c = \lambda_e\).

\end{proof}

\begin{comment}
\begin{algorithm}[caption={Builds the distributed circuit determined by the input hypergraph partition. The hypergraph partition is provided as an assignment \(qpuOf \colon \mathbb{N} \to \mathbb{N}\) which indicates the QPU number of the given wire},label={code:distributeVanilla}]
input: circuit, $qpuOf$
output: distributed
begin
  distributed $\gets$ $emptyCircuit$
  foreach wire in circuit do
    thisQPU = $qpuOf$(wire)
    activeConnections $\gets$ $\varnothing$
    foreach gate in wire do
      if gate == CNOT and $controlOf$(gate) == wire then
        targetQPU = $qpuOf$($targetOf$(gate))
        if targetQPU == thisQPU then
          distributed.$addCNOTAt$(wire,target)
        else
          ebit $\gets$ activeConnections.$at$(targetQPU)
          if ebit == null then
            ebit $\gets$ $distillEbit$(thisQPU, targetQPU)
            distributed.$addCatEntangler$(ebit, wire)
            activeConnections.$at$(targetQPU) $\gets$ ebit
          distributed.$addCNOTAt$(ebit,$targetOf$(gate))
      else
        distributed.$addGateAt$(gate,wire)
end
\end{algorithm}
\end{comment}

% Algorithm~\ref{code:distributeVanilla} performs the transformation from hypergraph partition to distributed circuit. Notice that this algorithm may alter the ordering of some of the gates, as a CNOT gate could be inserted before the previous gates on its target wire have been added. Some bookmarking must be kept to prevent this, but the details are straight-forward

\begin{remark} \normalfont
Figures~\ref{fig:vanillaCutsA}, \ref{fig:vanillaCutsB} and~\ref{fig:vanillaCutsC} provide a simple example of the one-to-one correspondence discussed in Theorem~\ref{thm:vanilla}. Interestingly, in Figure~\ref{fig:vanillaCutsC}, the second cat-entangler `copies' the information held by the local ebit half previously entangled with \(C\), instead of being directly coupled with \(C\). The latter option would also be correct\footnote{However, in that case, wires \(B\) and \(C\) should interchange places in the circuit representation, so it remains planar.}. Either way is represented by the same hypergraph partition, so in order to maintain our one-to-one correspondence, we should rather say that there is a bijection between hypergraph partitions and equivalence classes\footnote{Families of circuit distributions that are equivalent in the sense that their wires are allocated in the same way, and that the number of ebits required also matches.} of circuit distributions. Although for our algorithm all of the solutions in one such equivalence class are indistinguishable, some of them will offer a more decentralised network of ebits than others. Optimisations taking into account this fact could be done as post-processing of our proposed algorithm.
\end{remark}

A closer look at the bijection proposed in Theorem~\ref{thm:vanilla} reveals that we can transform back and forth between hypergraph partition and circuit distribution in polynomial time: We just need to read where each of the vertices/wires are allocated, and apply the primitive once for each of them -- which affects all the hyperedges/CNOTs on that vertex/wire. Hence, the time complexity of the transformation in either direction is \(O(n\cdot m)\), where \(n\) is the number of vertices/wires and \(m\) the number of hyperedges/CNOTs. This leads us to two results, one per direction of the bijection:

\begin{corollary} The best vanilla distribution of a circuit can be efficiently derived from an optimal partition of the hypergraph built from it by Algorithm~\ref{code:buildHypVanilla}.
\label{col:vanilla}
\end{corollary} \begin{proof}
We know it will be the best distribution thanks to Theorem~\ref{thm:vanilla}: The optimal partition will have the lowest possible \(\lambda_c\), and given that at any point \(\lambda_c = \lambda_e\), the corresponding circuit distribution will also have the lowest \(\lambda_e\) possible.

We say the circuit distribution is efficiently derived because the required transformations -- from input circuit to hypergraph, and from hypergraph partition to circuit distribution -- both run in polynomial time.

\end{proof}

\begin{corollary} The quantum circuit distribution problem is an NP-complete problem.
\end{corollary} \begin{proof}
To proof NP-completeness we simply need to show that, if the quantum circuit distribution problem can be solved in polynomial time, an NP-complete problem exists that can be solved in polynomial time. The hypergraph partitioning problem happens to be NP-complete \citep{NP-complete}, and Theorem~\ref{thm:vanilla} allows us to take any solution for the circuit distribution problem and provide the optimal partition of its hypergraph. The only caveat is that we need to be able to do this for any hypergraph so, given any hypergraph \(\mathcal{H}\), we must be able to build a non-distributed circuit \(\mathcal{C}\) that is represented by \(\mathcal{H}\) -- the opposite direction of what Algorithm~\ref{code:buildHypVanilla} does. There will be multiple such circuits; building one of these in polynomial time is possible, and the details are straight-forward.

\end{proof}

On the pessimistic side, this means that unless \(P=NP\), finding the best distribution of an arbitrary quantum circuit will take exponential time. On the positive side, in order to have fast compilers that prepare quantum algorithms to be run in distributed architecture, we will not need to look for better algorithms to solve our problem: we may use already heavily researched fast algorithms for hypergraph partitioning \citep{KaHyPart}, and the polynomial overhead of transforming back and forth between problems will be negligible. This is a common approach on classical computer science, where many problems related to compilers are also NP-complete.

\input{Figures/VanillaCuts}

\input{Figures/VanillaExample}

A simple circuit, its optimally partitioned hypergraph and the resulting distributed circuit are shown in Figure~\ref{fig:vanillaExample}. The obtained distribution is the most efficient one, in the sense described in the beginning of this section. Each of the QPUs can be set to implement its own local circuit, distilling ebits and using them along classical communication whenever indicated.


\subsection{Bringing CNOT gates together}
\label{pullCNOTs}

In \S\ref{NonLocalGates} we have shown that any 1-qubit gate in the Clifford+T set acting on the control wire of a CNOT gate, with the exception of the H gate, can commute with the CNOT up to some byproduct. Here we use this fact, applying some pre-processing on the input circuit that brings together nearby CNOT gates, allowing us to implement more non-local CNOT gates using a single ebit. Figure~\ref{fig:pulledCNOTexample} gives an example of how these transformations -- listed in Figure~\ref{fig:pullRules} -- can lead to a more efficient distribution of the circuit.

\input{Figures/PullExample}

The pre-processing procedure is fairly straight-forward: Exploring the circuit from left to right, whever a CNOT gate is found, use the transformations listed in Figure~\ref{fig:pullRules} to move it as early in the circuit as possible. The procedure introduces some additional \(X\) gates. Fortunately, \(X\) is its own inverse (i.e.\ \(XX = I\)) and every 1-qubit gate in Clifford+T can be interchanged with \(X\) in a simple way (as shown in Figure~\ref{fig:props}). Hence, we should not expect a significant increase in the depth of the circuit, as most byproduct gates will cancel each other out.

So far we have been talking about standard 1-qubit gates, but in practical circuits we are likely to find 1-qubit gates that are \textit{classically-controlled}, meaning that a classical signal (a bit, either \(0\) or \(1\)) decides whether the gate is applied or not. These are no issue for the distribution of the circuit, as this classical control may only require classical communication between QPUs. Concerning the pre-processing we just described, classically-controlled 1-qubit gates can commute with CNOT under the exact same circumstances as their uncontrolled version. The only difference is that, whenever a byproduct gate is created, we must make sure it is controlled by the same classical signal that controlled the original gate, as shown in Figure~\ref{fig:classicalControl}.

\input{Figures/ClassicalControl}

The same procedure can be used to commute 1-qubit gates across the target wire of the CNOT gates, although in this case, apart from \(H\), \(S\) and \(T\) gates can not commute either. This additional pre-processing would have no effect at all on the vanilla version of the algorithm, but it will be beneficial after we apply our next extension, which requires CNOT gates to be adjacent on the target wire.


\subsection{Using the remote-target method}
\label{BothEnds}

In \S\ref{NonLocalGates} we showed that the trick for implementing multiple CNOT gates using a single ebit also works if they share a common target wire (instead of the control wire). This makes our optimisation problem more intricate: Now, when the CNOTs are to be implemented non-locally, we can choose to implement them using the remote-control or remote-target method. For explanation purposes, we will use two different kinds of hyperedges in this subsection's figures, depending on whether their CNOTs are controlled by the same wire, or act on the same target (thicker line). 

\input{Figures/BothEndsChallenge}

Figure~\ref{fig:BothEndsChallenge}\textit{a)} shows a simple circuit where a CNOT \(\beta\) shares its target wire \(C\) with another CNOT \(\alpha\). The remote-target method would allow to implement these two non-locally, using a single ebit. We represent this fact in hypergraph \textit{c)}, as the three-vertex hyperedge. Gate \(\gamma\) shares its target with no other gate, so it is represented with an edge \((A,B)\). Hypergraph \textit{b)} is the one built by Algorithm~\ref{code:BuildHypVanilla}, and considers all non-local CNOTs are implemented as remote-control, so it is now gate \(\alpha\) the isolated edge \((B,C)\). If we were to partition the circuit as shown in the figure, hypergraph \textit{b)} would suggest that two qubits are required, when actually only one is enough, as shown by hypergraph \textit{c)}. But, if the partition is \(\{\{A\},\{B,C\}\}\) instead, hypergraph \textit{c)} would be the one overestimating the number of ebits needed. Hence, both hypergraphs \textit{b)} and \textit{c)} are biased. 

If we want to guarantee that the most efficient circuit distribution can always be found by a graph partitioner, we must find an alternative hypergraph representation of the circuit. Notice that it is not an option to simply find the optimal partition for both hypergraphs \textit{b)} and \textit{c)} and choose the one with least cuts: The best circuit distribution is unlikely to have all its CNOTs implemented in the same way. Therefore, our hypergraph representation must have the following characteristics:
\begin{enumerate}
  \item Both options of how to implement each CNOT are represented.
  \item A partition of the hypergraph must determine, for each non-local CNOT, which method should be used to implement it.
  \item The \(\lambda-1\) metric of a partition should accurately determine how many ebits are required to implement the circuit distribution it describes.
\end{enumerate}

\begin{algorithm}[caption={Builds the hypergraph of a given circuit, without choosing whether CNOT gates are implemented through common control or common target. This algorithm runs in time \(O(g)\), where \(g\) is the number of gates in the input circuit.}, label={code:buildHypBothEnds}]
input: circuit
output: (V,H)
begin
  V $\gets$ $\varnothing$
  H $\gets$ $\varnothing$
  hedge $\gets$ $\varnothing$
  foreach wire in circuit do
    V $\gets$ V $\cup$ {wire}
    H $\gets$ H $+$ {hedge}
    hedge $\gets$ {wire}
    hType $\gets$ $unknown$
    foreach gate in wire do
      V $\gets$ V $\cup$ {$labelOf$(gate)}
      if gate == CNOT then
        if $controlOf$(gate) == wire then
          if hType == $target$ then
            H $\gets$ H $+$ {hedge}
            hedge $\gets$ {wire}
          hType $\gets$ $control$
        if $targetOf$(gate) == wire then
          if hType == $control$ then
            H $\gets$ H $+$ {hedge}
            hedge $\gets$ {wire}  
          hType $\gets$ $target$
        hedge $\gets$ hedge $\cup$ {$labelOf$(gate)}
      else
        H $\gets$ H $+$ {hedge}
        hType $\gets$ $unknown$
        hedge $\gets$ {wire}
end
\end{algorithm}

\input{Figures/BothEndsProcess}

We propose our new hypergraph representation to be as \textit{d)} from Figure~\ref{fig:BothEndsChallenge}. Algorithm~\ref{code:BuildHypBothEnds} builds such a hypergraph for any given circuit, and Figure~\ref{fig:BothEndsProcess} shows how the hypergraph is built step by step for our running example. These hypergraphs satisfy the three requirements defined above: First, we include all of the control-hyperedges and target-hyperedges. For the second requirement, we give additional structure to the hypergraph, adding vertices that represent CNOT gates; how a CNOT is implemented will be determined by the block its CNOT-vertex is assigned to. The third requirement is the most subtle one. Intuitively, we satisfy it by, imposing that each CNOT-vertex participates in only two hyperedges; one connecting it to its control wire-vertex, the other to its target. A more detailed account of how this third requirement holds is given in the proof of Theorem~\ref{thm:bothEnds}. Corollary~\ref{col:bothEnds} confirms that the optimal partition of our hypergraph determines the most efficient circuit distribution.


\begin{theorem}
 Given any circuit \(\mathcal{C}\), and its hypergraph \(\mathcal{H}\) generated by Algorithm~\ref{code:buildHypBothEnds}, there is a bijection between partitions of \(\mathcal{H}\) with \(\lambda_c\) cuts and distributions of \(\mathcal{C}\) using \(\lambda_e\) ebits.
 \label{thm:bothEnds}
\end{theorem}
\begin{proof}
We define the same trivial configuration in Theorem~\ref{thm:vanilla}. In the case of \S\ref{Vanilla}, the CNOT operation itself was always applied in the same QPU as its target, regardless of the CNOT being local or not (see Figure~\ref{fig:nonlocalCNOTs}). Thus, the primitive from Theorem~\ref{thm:vanilla} for moving a wire-vertex \(x\) around is defined here with the extra constraint that all CNOT-vertices connected by a target-hyperedge to \(x\) must move with it to the same block/QPU \(x\) does. 

In order to reach any hypergraph partition we need to add a primitive that allows us to move a CNOT-vertex \(x\) independently from its wire-vertices. Conversely, in order to reach any arbitrary circuit distribution, we need to be able to change the QPU where a CNOT gate \(x\) is implemented. This pair of primitives is defined to correspond one-to-one to each other. Let's consider the four distinct cases of how \(x\) may be allocated regarding its neighbouring wire-vertices acting as CNOT \(x\)'s control \(c_x\) and target \(t_x\):
\begin{itemize}
  \item \textit{Local}: The three vertices \(x\), \(c_x\) and \(t_x\) are in the same block \(i\). In this case, \(x\)'s allocation contributes to neither a cut on its control-hyperedge nor a cut on its target-hyperedge. The CNOT gate is implemented locally in QPU \(i\), so no ebit is required to implement it.
  \item \textit{Remote control}: Both \(x\) and \(t_x\) are in a block \(i\), while \(c_x\) is in a different block \(j\). In this case, \(x\)'s allocation contributes only to a cut on its control-hyperedge. An ebit is required to implement the CNOT, which may be also used to implement other CNOTs in QPU \(i\) that are also controlled by \(c_x\). This is the case from Figure~\ref{fig:nonlocalCNOTs}, and the only one available for the implementation of non-local CNOTs in the vanilla algorithm.
  \item \textit{Remote target}: Both \(x\) and \(c_x\) are in a block \(i\), while \(t_x\) is in a different block \(j\). In this case, \(x\)'s allocation contributes only to a cut on its target-hyperedge. Again, an ebit is required to implement the CNOT, although in this case other CNOTs in QPU \(i\) with common \(t_x\) target may share that ebit.
  \item \textit{External}: The three vertices are in separated blocks, with \(x\) in some block \(i\). An example of this situation is shown in Figure~\ref{fig:farCNOT}. In this case, \(x\)'s allocation contributes to both a cut on its control-hyperedge and on its target-hyperedge. In this case, two ebits are required; the one used to access \(c_x\) may be shared with other CNOT gates in \(i\) that have that wire as common control, while the ebit used to access \(t_x\) may be shared with CNOTs in \(i\) that have that target in common.
\end{itemize} 

The proof by induction discussed in Theorem~\ref{thm:vanilla} holds here if we manage to show that any application of this CNOT-vertex allocation primitive still preserves \(\lambda_c = \lambda_e\). Changing the allocation of a CNOT-vertex \(x\) may change its situation among the four cases above. As detailed there, in each case \(x\)'s allocation contributes to the same amount of cuts as ebits the CNOT \(x\) requires. Hence, changing the allocation of \(x\) always preserves \(\lambda_c = \lambda_e\).

\end{proof}

\input{Figures/FarCNOT}

The procedure for distributing the circuit following a given hypergraph partition is very similar to that in the vanilla version of the algorithm, now taking into account the new primitive defined in Theorem~\ref{thm:bothEnds}. The time complexity of the procedure still is \(O(n\cdot m)\), where \(n\) is the total number of vertices and \(m\) is the number of hyperedges. Also, notice that the cat-entangler and the cat-disentangler are slightly different whether the CNOTs are implemented through remote-control or remote-target (see Figure~\ref{fig:CNOTtargetProof}).

\begin{corollary}
The best distribution of a circuit can be efficiently derived from an optimal partition of the hypergraph built from it by Algorithm~\ref{code:buildHypBothEnds}.
\label{col:bothEnds}
\end{corollary}
\begin{proof}
Directly follows from Theorem~\ref{thm:bothEnds}, by the same argument given for Corollary~\ref{col:vanilla}. 

\end{proof}

\begin{corollary}
The distributed circuit we obtain using the vanilla algorithm (from \S\ref{Vanilla}) is the same as the one obtained if we restrict the approach in this subsection so either:
\begin{enumerate}
  \renewcommand{\theenumi}{\alph{enumi})}
  \item The remote-target method is never used.
  \item Our hypergraph partitioner never cuts target-hyperedges.
  \item CNOT gates are always executed in their target QPU.
\end{enumerate}
All of these restrictions are equivalent.
\end{corollary}

The hypergraph built by Algorithm~\ref{code:buildHypBothEnds} has one caveat: When discussing load-balancing in \S\ref{EfficientDistrib}, we explained that we were interested in allocating a uniform number of wires to each QPU. Previously, the hypergraph partitioner took care of this, as it tried to assign a uniform number of vertices to each block. But now, the hypergraph partitioner has no way of distinguishing between `wire' vertices and `CNOT' vertices, the latter being an artificial gadget that should not count towards load-balancing. The solution is simple, instead of the standard hypergraph partition problem, we apply a version of it where vertices can have a weight assigned (see Appendix~\ref{chap:HypPart}). Then, each wire-vertex is given weight \(1\), and each CNOT-vertex is given weight \(0\), effectively ignoring them for the load-balancing aspect.

The case illustrated in Figure~\ref{fig:farCNOT} can be seen intuitively as passing a message through a middle-man. Sometimes, using communication through an already available middle-man is better than putting up a full blown connection just for a single message. The hypergraph partitioner acting on the hypergraph built by Algorithm~\ref{code:buildHypBothEnds} will automatically use this strategy whenever it reduces the number of ebits required. Some criticism is relevant here: if we put no constraint on the exploitation of `middle-men' QPUs, it may happen that communication across many of the QPUs all use the same middle-man QPU to deliver their messages, potentially creating a bottle neck. We see two solutions:

%Notice, however, that this trick only allows to implement a single CNOT with both target and control wires in some particular QPUs. When the CNOT shares one of its wires with multiple CNOTs, it will often be best to use the remote-control or remote-target method to implement all of them together. This trick will be useful whenever there are stray CNOT gates that can not be efficiently grouped with other CNOTs.

\begin{enumerate}
\item Specialise your hardware as centralised communication network, where the `middle-man' QPU has a similar role to a classical server. The server should be capable of managing a large number of ebits fast and reliably. This is the natural option if the algorithms we wish to run have an intrinsically centralised behaviour -- for instance, if all the gates are controlled by the same wire.

\item In case we wish to have a decentralised network, we will need to find a way to ensure the hypergraph partition we get has some kind of load-balancing the usage of ebits. Fortunately, there is a simple way to do this: instead of giving CNOT vertices weight \(0\) as we previously discussed, we may give them some weight \(\mu > 0\) that indicates how relevant communication load-balancing is in comparison to the uniformity of wire allocation across QPUs. Even better, we could use a custom version of the hypergraph partitioning problem where we provide three parameters instead of two, \(k,\varepsilon,\eta\), where now \(\varepsilon\) acts as the tolerance for imbalance of wire-vertices, while \(\eta\) is a separate tolerance for imbalance of CNOT-vertices, both tolerances being enforced in any partition.
\end{enumerate}

%Across the figures of this subsection we have drawn differently hyperedges that group CNOTs with remote-control or remote-target. However, it should be noticed that the hypergraph partitioner does not use this information at any point. This distinction is made for explanation purposes, and it is only relevant when building the distributed version of the circuit. 

As a wrap up of this section, Figure~\ref{fig:modes} showd the same circuit being distributed in four different ways: with or without the extension from \S\ref{pullCNOTs} and with or without the extension from \S\ref{BothEnds}. This provides a simple example where both extensions are shown to reduce the number of ebits required to distribute a circuit.

\input{Figures/Modes}

\section{Interchanging CNOT gates}

When applied to disjoint sets of wires, CNOT gates commute trivially. If one of the wires is in common, in case it has the same role for both CNOTs (control or target), we can take advantage of it and implement both gates using a single ebit. If both wires are in common and have the same role, the CNOTs cancel each other. But what happens if two CNOTs act on the same wire with different roles? In that case, we can still interchange the gates as in Figure~\ref{fig:interchangeRule}, but that creates an additional CNOT per interchange.

\input{Figures/InterchangeRule}

\input{Figures/InterchangeChallenge}

It may seem like pre-processing the circuit so it has the minimum possible number of CNOT gates would always be the best option for partitioning. However, this is not always true, as shown in Figure~\ref{fig:interchangeChallenge}. In some cases interchanging CNOTs may unlock a more efficient distribution of the circuit. Therefore, the effect of CNOT interchange should also be encoded in our hypergraph representation, if we were to exploit its full potential. However, encoding that information in a hypergraph is not natural, due to the following reasons:

\begin{itemize}
  \item \textit{The way CNOT gates are ordered in the circuit is important}: This is something we omit in the hypergraphs built by Algorithm~\ref{code:buildHypBothEnds}; looking at the final hypergraph in Figure~\ref{fig:BothEndsProcess}, we can not tell whether \(\alpha\) goes before or after \(\beta\). This information is key when interchanging, as it will determine which are the new neighbours of the interchanged CNOTs. A possible approach would be to impose that every hyperedge is an ordered list of vertices\footnote{\, For instance, the first vertex corresponding to a wire and the rest, corresponding to the different CNOT gates, ordered as in the circuit.}. However, the standard hypergraph partitioning problem does not take into account such ordering. We would need to define a custom hypergraph partitioning problem in order to manage this new aspect.

  \item \textit{Interchanging CNOT gates adds new CNOTs}: The CNOT interchange problem is substantially different from the one we discussed and solved in \S\ref{BothEnds}. The essence of our solution was to represent all of the potential choices in a single hypergraph. However, if were to interchange a pair of CNOTs, new choices would become available: Is it worth to interchange the CNOTs again with their new neighbours? Should the byproduct CNOT be itself interchanged further? Although the number of options to take into account is finite, it increases considerably fast. Furthermore, each choice would not be independent from the rest -- as some interchanges are only available if others have been done before -- so the structure of the hypergraph would likely be quite complex in order to accommodate this information.
\end{itemize}

Instead of encoding this choice within the hypergraph partioning problem, we may abandon the idea of guaranteeing the optimal solution, and approach this problem through pre-processing and post-processing. We suggest that a reasonable approach in that case would be to:
\begin{enumerate} 
\item Apply a pre-processing phase that finds an equivalent circuit whose hypergraph has the minimum possible number of hyperedges. 
\item Apply the procedure described in the previous section, which decides how to partition the circuit. 
\item Apply a post-processing phase that exhaustively explores each possible interchange of CNOTs. Those that reduce the number of ebits required to implement the partition are used.
\end{enumerate}

\textbf{TODO}: Is this a greedy algorithm? (most probably, a greedy algorithm won't be optimal... maybe dynamic programming?) If I have time I should I give more details on the strategy? Maybe implement it.

\section{An upper bound}

\textbf{TODO}: Finally, for the sake of comparison, we will use some theoretical results on quantum circuit decomposition, in order to estimate an upper bound of the number of ebits needed to distribute any quantum process on \(N\) qubits.

\textbf{TODO}: Discuss structured vs unstructured as the reason why we expect our algorithm to perform better.

\textbf{NOTE}: I probably won't do this section. The upper bound I've got is very loose, and the discussion does not seem to fit that well into this thesis.