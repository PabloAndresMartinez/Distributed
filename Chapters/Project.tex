\chapter{Automated Distribution of Quantum Algorithms}
\label{chap:Project}

\section{Implementing non-local CNOT gates}
\label{NonLocalGates}

In \S~\ref{IntroDistributing}, we explained the proposal by~\citet{NonLocalCNOT} of how to implent a non-local CNOT. We will now extend their results.

The first thing to notice is that the CNOT gates need not immediately follow one another. Some of the 1-qubit gates from the \texttt{Clifford+T} set commute with the CNOT. We may transform a circuit so the controls of different CNOT gates are brought together. Some of the gates do not commute, but they can be interchanged with the CNOT if an additional 1-qubit gate is added. All of these transformations are shown in Figures~\textbf{TODO}. These can be checked by calculating the corresponding matrices and verifying they match.

\textbf{TODO}: Figures of how to push gates through control.

The second improvement comes by realising that the trick used to implement multiple CNOT gates controlled by the same wire can also be applied if multiple CNOT gates target the same qubit. The derivation is shown in Figure~\ref{CNOTtargetProof}, which uses some of the properties listed in \S~\ref{Models}.

\textbf{TODO}: CNOTtargetProof


\section{Finding an efficient distribution}
\label{EfficientDistrib}

In this section we explain how we search for a suitable partition of the circuit. As discussed in \S~\ref{DQC_Architecture}, our notion of an optimal distribution of a given circuit is one such that:

\begin{itemize}
  \item \textit{Minimal amount of quantum communication} between the QPUs as possible, i.e\ it requires as little number of ebits as possible. In comparison, message passing of classical bits is considered negligible.
  \item The \textit{QPUs should be load-balanced} up to a tolerance margin. Our notion of load-balance is that the different QPUs have a similar number of qubits from the original circuit assigned to them, i.e.\ we care about having a uniform breadth of local circuits. A uniform depth would be desirable, however, the distributed circuit depth is inherited from the original circuit, as none of our distribution techniques change the depth in a significant way. Hence, we will assume that circuit depth reduction methods, such as the one described by~\citet{DepthReduction}, have already been applied on the input circuit (and they could be also applied to each QPU's local circuit after distribution). As circuit depth is not something we aim to optimise, we consider the cost of local gates negligible.
\end{itemize}

The problem at hand is similar to the \((k,\varepsilon\) \textit{graph partitioning} problem, where a graph partition in \(k\) subgraphs has to be found, minimising the number of \textit{cut edges} -- edges that have their incident vertices in different blocks -- and ensuring the number of vertices in each block is within the \(\varepsilon\) tolerance factor: \((1 \pm \varepsilon)\frac{N}{k}\), where \(N\) is the total number of vertices in the graph. In Table~\ref{tab:matching} we list the matches between these two problems.

\begin{table}
\label{tab:matching}
\caption{Correspondence between the graph partitioning problem and the efficient distribution of quantum circuits.}
\centering
\begin{tabular}{|c|c|}
\hline
\textit{Graph partitioning} & \textit{Efficient distribution} \\
\hline
Vertices & Wires \\
Edges & CNOT gates \\
Partitioned graph & Distributed circuit \\
Subgraph & QPU \\
Min. cut edges & Min. non-local gates \\
Uniform subgraph size & Load balance \\
\hline
\end{tabular}
\end{table}

But there is a caveat. If we use graph partitioning naively, we will not be exploiting the fact that multiple CNOT gates may be implemented using a single ebit. In what follows, we will explain how to make use of \textit{hypergraph} partitioning, instead of simple graph partitioning, to account for this aspect. A more detailed review of hypergraph partition is given in Appendix~\ref{chap:HypPart}, here we summarise the key concepts:

\begin{itemize}
  \item Hypergraphs extend graphs to accommodate edges that may have more than two incident vertices. More formally, a hypergraph is a pair of sets \((V,H)\), where \(V\) is the set of vertices and \(H \subseteq 2^V\) is the \textit{collection}\footnote{We will allow multiple hyperedges connecting the same vertices, in the same way as multigraphs allow multiple edges across any pair of edges.} of hyperedges. Each hyperedge is represented as the subset of vertices from \(V\) it connects. We will not consider any notion of directionality, i.e.\ all vertices of a hyperedge play the same role.
  \item Hypergraph partitioning follows the same premise as graph partitioning. The user provides a hypergraph and the two parameters \((k,\varepsilon)\), which have the exact same meaning as before. What the problem now attempts to minimise is a metric known as \(\lambda\!-\!1\), which is defined as follows: given a partition of the hypergraph, the function \(\lambda\colon H \to \mathbb{N}\) pairs each hyperedge with the number of different \textit{blocks}\footnote{The term \textit{block} is often used to refer to each of the sub-hypergraphs that comprise the hypergraph partition. It is the term we will use throughout this thesis.} its vertices are in. Then, \(\lambda\!-\!1 = \sum_{h \in H} \lambda(h) - 1\) provides a measure of not only how many hyperedges are `cut' but also across how many blocks they are connecting\footnote{Simply minimising the number of hyperedges `cut' is also an often used approach, but it is not as useful for our problem.}.
\end{itemize}

In the following subsections, we explain how hypergraph partitioning can be used to find the best distribution of a circuit. First, we only use the implementation of non-local gates described by~\citet{NonLocalCNOT} and reviewed in \S~\ref{IntroDistributing}. Later on, we extend the algorithm to include the improvements we have proposed in \S~\ref{NonLocalGates}.

\subsection{Vanilla algorithm}

The key concept is how to use hyperedges to represent a collection of CNOT gates that, in case of being non-local, could all be implemented using a single ebit. As we already explained in \S~\ref{IntroDistributing}, a single ebit may be used if all the CNOT gates are controlled by the same wire, and there are no other gates in between their connections to that wire, as in Figure~\ref{fig:multipleCNOTs}). Therefore, for such a collection of CNOT gates, we will create a single hyperedge whose vertices correspond to the controlling wire and each of the different wires the CNOT gates target. The algorithm is described in Algorithm~\ref{code:buildHypVanilla}.

\begin{algorithm}[caption={Builds the hypergraph of a given circuit. \(H\) may contain multiple hyperedges connecting the same vertices.}, label={code:buildHypVanilla}]
input: circuit
output: (V,H)
begin
  V $\gets$ $\varnothing$
  H $\gets$ $\varnothing$
  hedge $\gets$ $\varnothing$
  foreach wire in circuit do
    V $\gets$ V $+$ {wire}
    H $\gets$ H $+$ {hedge}
    hedge $\gets$ {wire}
    foreach gate in wire do
      if gate == CNOT and $controlOf$(gate) == wire then
        hedge $\gets$ hedge $+$ {$targetOf$(gate)}
      else
        H $\gets$ H $+$ {hedge}
        hedge $\gets$ {wire}
end
\end{algorithm}

We then solve the hypergraph partitioning problem (see Appendix~\ref{chap:HypPart}) on the resulting hypergraph. Whenever a hyperedge is cut, the qubits the CNOT gates act on are assigned to different QPUs. Those target qubits which fall in the same QPU as the control qubit will have their CNOT gate implemented locally. The other CNOT gates will be non-local, all of them implemented by the same ebit. Clearly, if the hyperedge is not cut, all the CNOT gates it represents will be local in some QPU. If the hyperedge is cut more than once, i.e.\ its vertices are split among more than two blocks, then we will require additional ebits. As we previously defined, the function \(\lambda\colon H \to \mathbb{N}\) tells us how many blocks a cut hyperedge connects. In order to connect \(\lambda(h)\) blocks, we need at least \(\lambda(h)-1\) block-to-block connections: \(\lambda(h)-1\) ebits. Therefore, the \(\lambda-1\) metric is the one we will ask our hypergraph partitioner to minimise.

Notice that all CNOT gates from the input circuit are represented once and only once in the hypergraph. This is essential for the well functioning of our algorithm. Besides, it may be surprising that our hyperedges do not indicate which of the vertices is the control wire. However, that information is irrelevant at the partitioning level: every time a hyperedge is cut, we will require an ebit to implement the non-local gates, no matter on which side the control wire falls. That information is only relevant when transforming the circuit into its distributed form, which is the next step of our algorithm. 

The hypergraph partition provides us with an assignment of each wire to a QPU. Using it, we transform the original circuit to obtain its distributed version. To do so, we find each group of CNOT gates corresponding to a cut hyperedge\footnote{This can be done easily if we kept some bookmarking while building the hypergraph as in Algorithm~\ref{code:buildHypVanilla}}, then we insert \(\lambda(h)-1\) cat-entanglers (Figure~\ref{fig:cat-entangler}) -- one per pair of QPUs that must be connected -- just before the CNOT gates, and \(\lambda(h)-1\) cat-disentanglers (Figure~\ref{fig:cat-disentangler}) right after them. Finally, each of the non-local CNOTs are changed so their control wire is the corresponding QPU's local ebit half.

%Notice that if procedure from Algorithm~\ref{code:distribution} is applied carelessly, the ordering of the gates could be altered, as a CNOT gate could be inserted before the previous gates on the target wire have been added. Some bookmarking must be kept to prevent this, but the details are straight-forward.

\begin{comment}
\begin{algorithm}[caption={Algorithm for distributing a circuit using an assignment \(qpuOf \colon \mathbb{N} \to \mathbb{N}\) which indicates the QPU number of the given wire},label={code:distribution}]
input: circuit, $qpuOf$
output: distributed
begin
  distributed $\gets$ $emptyCircuit$
  foreach wire in circuit do
    thisQPU = $qpuOf$(wire)
    activeConnections $\gets$ $\varnothing$
    foreach gate in wire do
      if gate == CNOT and $controlOf$(gate) == wire then
        targetQPU = $qpuOf$($targetOf$(gate))
        if targetQPU == thisQPU then
          distributed.$addCNOTAt$(wire,target)
        else
          ebit $\gets$ activeConnections.$at$(targetQPU)
          if ebit == null then
            ebit $\gets$ $distillEbit$(thisQPU, targetQPU)
            distributed.$addCatEntangler$(ebit, wire)
            activeConnections.$at$(targetQPU) $\gets$ ebit
          distributed.$addCNOTAt$(ebit,$targetOf$(gate))
      else
        distributed.$addGateAt$(gate,wire)
end
\end{algorithm}
\end{comment}


\textbf{TODO}: A figure showing a simple circuit, its hypergraph and its distributed circuit (with cat-(dis)entangler as a box). It'd be great if the example on these three subsections was the same (fig:distribProcess)

A simple example of the distribution process is shown in Figure~\ref{fig:distribProcess}. The resulting circuit is a distributed version of the original one, that is efficient in the sense described in \S~\ref{EfficientDistrib}. Each of the QPUs can be set to implement its own local circuit, using its local ebit halves and classical communication whenever indicated.


\subsection{Bringing CNOT gates together}
\label{pullCNOTs}

In \S~\ref{NonLocalGates} we have shown that any 1-qubit gate in the \texttt{Clifford+T} set acting on the control wire of a CNOT gate, with the exception of the Hadamard gate, can commute with the CNOT up to some byproduct. Here we use this fact, applying some preprocessing on the input circuit that brings together nearby CNOT gates, allowing us to implement more non-local CNOT gates using a single ebit. Figure~\ref{fig:pulledCNOTexample} gives an example of how these transformations -- listed in Figures \textbf{TODO} -- can lead to a more efficient distribution of the circuit.

\textbf{TODO} Figure with (hopefully) the same circuit as the previous figure, its version after CNOTpulling and its hypergraph partition, which should have less lambda-1 (fig:pulledCNOTexample)

The preprocessing procedure is fairly straight-forward: From the beginning of the circuit, find each CNOT gate and use the transformations listed in Figures~\textbf{TODO} to move every CNOT gate as early in the circuit as possible. The procedure introduces some additional \(X\) gates, due to the transformations in Figures~\textbf{TODO}. Fortunately, \(X\) is its own inverse (i.e.\ \(XX = I\)) and every 1-qubit gate in \texttt{Clifford+T} can be interchanged with \(X\) in a simple way (as shown in Figures~\textbf{TODO}). Hence, we should not expect a significant increase in the depth of the circuit: most byproduct gates will cancel each other out.

So far we have been talking about standard 1-qubit gates, but in practical circuits we are likely to find 1-qubit gates that are \textit{classically-controlled}, meaning that a classical signal (a bit, either \(0\) or \(1\)) decides whether the gate is applied or not. This is no concern for our distribution of the circuit, as this classical control may only require classical communication between QPUs, whose cost we discussed to be negligible in comparison to quantum communication through ebits (see \S~\ref{EfficientDistrib}). Concerning the preprocessing we just described, classically-controlled 1-qubit gates can commute with CNOT under the exact same circumstances as their uncontrolled version. The only difference is that, whenever a byproduct gate is created, we must make sure it is controlled by the same classical signal that spawned it, as shown in Figure~\ref{fig:classicalControl}.

\textbf{TODO} Figure with an X gate classically controlled before the control of a CNOT. Then the resulting circuit after exchanging them (fig:classicalControl)

This preprocessing can commute 1-qubit gates both across the control wire and the target wire of the CNOT gate (although in the latter case, apart from \(H\), \(S\) and \(T\) can not commute either). This has no effect at all on the vanilla version of the algorithm, but it will be beneficial after we apply our next extension, which requires CNOT gates to be directly contiguous on the target wire.


\subsection{CNOT gates joined on target}
\label{BothEnds}

In \S~\ref{NonLocalGates} (see Figure~\ref{CNOTtargetProof}) we showed that the trick for implementing multiple CNOT gates using a single ebit also works if they are contiguous on the target wire (instead of the control wire). This makes our optimisation problem more intricate: before, for each CNOT gate we only had two options, whether to make it local or non-local -- i.e.\ whether to cut the hyperedges or not -- but now, when the CNOT are to be implemented non-locally, there are two possible choices of how to do it, which we will represent as two different kinds of hyperedges, whether what their CNOTs have in common is the control or the target. Figure~\ref{fig:BothEndsSimple} shows a simple circuit where neither of the options is a priori better. 

\textbf{TODO}: Figure where with 3 CNOTs we show that depending on how they are grouped together, we may gain something or not, which ultimately depends on how the hypergraph is split. Include both hypergraphs (fig:BothEndsSimple) Caption: The hypergraph of the circuit built as in Algorithm~\ref{code:buildHypVanilla} uses the common control of gates \(\alpha\) and \(\beta\), while the other one is built similarly, but on common target. Different line format for the hyperedges whether control or target.

Now, imagine such a circuit to be a fragment of a larger one where, for instance, allocating wires \(A\) and \(B\) in one QPU and wire \(C\) in another is the most efficient configuration. As shown in Figure~\ref{fig:BothEndsChallenge}, in this particular case using the trick on the common target saves us one ebit. Conversely, if \(A\) were the wire on a separate QPU and \(B,C\) were together, using the common control would be best. The conclusion is that the choice of using control or target hyperedges on a particular fragment of the circuit is dependent on the overall partitioning. However, if we intend to use hypergraph partitioning, these CNOT gates must somehow be represented in the hypergraph. The best solution would be to build the hypergraph in such a way that the decision of using control or target hyperedges is not done a priori, but by the hypergraph partitioner itself. A naive approach, also shown in Figure~\ref{fig:BothEndsChallenge}, would be to include all of the hyperedges, both of control and target type, in a single hypergraph. However, then either partitioning of the resulting hypergraph is cutting three hyperedges, so the hypergraph partitioner sees no difference between the two options, preventing it from taking into account this subtlety when optimising.

\textbf{TODO}: Figure of hypergraphs from prev Fig; with control hyps, target hyps, naively. The dashed lines represent two hypothetical ways of partitioning the hypergraph. Different line format for the hyperedges whether control or target (fig:BothEndsChallenge)

We propose to build the hypergraph as in Algorithm~\ref{code:buildHypBothEnds}. This hypergraph requires an additional vertex per CNOT in the circuit, and the block where the hypergraph partitioner decides to include that vertex in dictates whether the CNOT is implemented as a control or target hyperedge. In Figure~\ref{fig:BothEndsProcess} shows how the hypergraph is built step by step for our running example. 

\begin{algorithm}[caption={Builds the hypergraph of a given circuit, without choosing whether CNOT gates are implemented through common control or common target. \(H\) may contain multiple hyperedges connecting the same vertices.}, label={code:buildHypBothEnds}]
input: circuit
output: (V,H)
begin
  V $\gets$ $\varnothing$
  H $\gets$ $\varnothing$
  hedge $\gets$ $\varnothing$
  foreach wire in circuit do
    V $\gets$ V $+$ {wire}
    H $\gets$ H $+$ {hedge}
    hedge $\gets$ {wire}
    hType $\gets$ $unknown$
    foreach gate in wire do
      if gate == CNOT then
        if $controlOf$(gate) == wire then
          if hType == $target$ then
            H $\gets$ H $+$ {hedge}
            hedge $\gets$ {wire}
          hType $\gets$ $control$
        if $targetOf$(gate) == wire then
          if hType == $control$ then
            H $\gets$ H $+$ {hedge}
            hedge $\gets$ {wire}  
          hType $\gets$ $target$
        hedge $\gets$ hedge $+$ {$labelOf$(gate)}
      else
        H $\gets$ H $+$ {hedge}
        hType $\gets$ $unknown$
        hedge $\gets$ {wire}
end
\end{algorithm}

\textbf{TODO}: Figure where the hypergraph for the three CNOTs example is built step by step (as in the Algorithm above) (fig:BothEndsProcess)

The hypergraph built by Algorithm~\ref{code:buildHypBothEnds} has one caveat: When discussing load-balancing in \S~\ref{EfficientDistrib}, we explained that we were interested in allocating a uniform number of wires on each QPU. Previously, the hypergraph partitioner took care of this, as it tries to assign a uniform number of vertices to each block. But now, the hypergraph partitioner has no way of distinguishing between `wire' vertices and `CNOT' vertices, the latter being an artificial gadget that should not count towards load-balancing. The solution is simple, instead of the standard hypergraph partition problem, we apply a version of it where vertices can have a weight assigned (see Appendix~\ref{chap:HypPart}). Then, each `wire' vertex is given weight \(1\), and each `CNOT' vertex is given weight \(0\), effectively ignoring them for the load-balancing aspect.

We now proceed to analyse, case by case, what is the correspondence of a cut hyperedge in the circuit:

\begin{enumerate}
\item \textbf{TODO}
\end{enumerate}

Thus, it should be clear that each of the possible ways the vertex set can be partitioned indicates a different way of distributing the circuit: The allocation of wires to QPUs correspond to which block the wire-vertices have been assigned, while each CNOT is implemented in the QPU where its CNOT-vertex has been assigned. Each time a hyperedge is cut implies the need of an ebit, and no additional ebits are required. Therefore, given any circuit, an optimal partition of the hypergraph built by Algorithm~\ref{code:buildHypBothEnds} determines the most efficient way of using the common-control and common-target tricks to distribute the circuit.

Across the figures of this subsection we have drawn differently hyperedges which group CNOTs with common-control or common-target. However, it should be noticed that the hypergraph partitioner does not need to use this information at any point. This distinction is made for explanation purposes only. Once a hypergraph partition is decided, cat-entanglers and cat-disentanglers are added before and after each group of CNOTs that corresponds to a cut hyperedge. Then, the control and/or target of each CNOT gate is adjusted accordingly, so they connect to their local ebit half.

As a wrap up of this section, in Figure~\ref{fig:modes} we show the same circuit being distributed in four different ways: with or without the extension from \S~\ref{pullCNOTs} and with or without the extension from \S~\ref{BothEnds}. This provides a simple example where both extensions are shown to reduce the number of ebits required to distribute a circuit.

\textbf{TODO} Figure example `interesting' with different modes (fig:modes)

\section{Interchanging CNOT gates}

CNOT gates can be interchanged trivially when none of their wires are the same. When one of the wires is in common and has the same role (control or target), we can take advantage of it and implement them using a single ebit. If both wires are in common and with the same role, the CNOTs cancel each other. But what happens if two CNOTs act on the same wire with different roles? In that case, we can still interchange the gates as in Figures~\textbf{TODO}, but that creates additional CNOTs.

\textbf{TODO}: Interchange challenge (picture from phone) (fig:interchangeChallenge)

It may seem like preprocessing the circuit so it has the minimum possible number of CNOT gates would always be the best option for partitioning. However, this is not always true, as shown in Figure~\ref{fig:interchangeChallenge}. In some cases, interchanging CNOTs may unlock a more efficient partitioning of the circuit. In other cases, it will have no benefit, while adding an additional CNOT to take into account when partitioning. This compromise prevents us from knowing a priori the best choice. Providing the hypergraph partitioner with the flexibility of deciding either to interchange a particular pair of CNOTs or not -- in the same spirit we did in \S~\ref{BothEnds} -- would be the best solution. However, encoding such a choice in a hypergraph partitioning problem is very difficult, due to the following reasons:

\begin{enumerate}
  \item The way CNOT gates are ordered in the circuit is important. This is something we omit in the hypergraph representation -- looking at the final hypergraph in Figure~\ref{fig:BothEndsProcess}, we can not tell whether \(\alpha\) goes before or after \(\beta\). This information is key when interchanging, as it will dictate which are the new neighbours of the interchanged CNOTs. This could potentially be accounted for by imposing that any hyperedge is an ordered list of vertices\footnote{For instance, the first vertex corresponding to a circuit wire, and the other corresponding to the different CNOT gates, ordered as in the circuit}. However, the standard hypergraph partitioning problem does not take into account the ordering of vertices, so we may need to define a custom hypergraph partitioning problem where this information is somehow taken into account.
  \item Interchanging CNOT gates adds new CNOTs. This problem is substantially different from the problem in \S~\ref{BothEnds}, where the count of CNOTs remained the same, the only degree of freedom being whether each CNOT was implemented as control or as target hyperedge. The essence of our solution in \S~\ref{BothEnds} is to represent all of the options in the hypergraph. However, if were to interchange a pair of CNOTs, new choices become available: is it worth to interchange the CNOTs again with their new neighbours? Should the byproduct CNOT, generated by the previous interchange, be itself interchanged further? Although the number of options to take into account is finite, it is considerably larger. And what is worse, each choice would not be independent from the rest -- as some interchanges are only available if others have been done before -- so the structure of the hypergraph would likely need to be quite complex to accommodate this aspect.
\end{enumerate}

We propose to apply some postprocessing once the circuit has been partitioned, exhaustively applying the transformations in Figures~\textbf{TODO} to each pair of potentially interchangeable CNOTs, keeping those transformations that reduced the ebit count. \textbf{TODO} Is this a greedy algorithm? should I give more details on the strategy?

\section{An upper bound}

\textbf{TODO}: This section

Finally, for the sake of comparison, we will use some theoretical results on quantum circuit decomposition, in order to estimate an upper bound of the number of ebits needed to distribute any quantum process on \(N\) qubits.

Discuss structured vs unstructured, this being the reason why we expect our algorithm to perform way better.
