\chapter{Conclusions}
\label{chap:Conclusions}

In this work, we have proposed an algorithm that distributes any quantum circuit across a given number of QPUs. As far as we know, this is a novel contribution, as no other procedure for the automated distribution of quantum circuits can be found in the literature. Our algorithm minimises the ebit count, meaning that it yields minimal quantum communication across QPUs.

We make use of the work by \citet{NonLocalCNOT}, where groups of non-local CNOTs are implemented using a single ebit. We refer to their approach as the remote-control method. In \S\ref{NonLocalGates} we gave two extensions of their work. First, we argued that in order to be in the same group, CNOTs are not required to be contiguous in the input circuit, as we may interchange CNOTs with other gates from Clifford+T to bring them together. Second, we showed that a construction dual to the remote-control method was also possible. Our main contribution was described in \S\ref{EfficientDistrib}, where we proposed the vanilla version of our algorithm -- that uses the results from the previous paper -- and two extensions of it, corresponding to the two extensions we previously introduced. 

Our algorithm reduces the problem of efficiently distributing a quantum circuit to the problem of hypergraph partitioning. As we discussed at the beginning of \S\ref{EfficientDistrib}, hyperedges allow us to represent groups of CNOTs that share a wire in common. Using standard graph partitioning instead would correspond to the naive approach of creating an edge per individual CNOT. In that case, we would require an ebit per non-local CNOT. Using our approach, the number of ebits is in many cases considerably smaller than the number of non-local CNOTs, as shown in the figures from Chapter~\ref{chap:Results}.

In Chapter~\ref{chap:Results} we analysed how well our algorithm distributed some benchmark quantum circuits. Figure~\ref{fig:results1} showed that enabling both of our algorithm extensions is not always the best option in practice. We argued that this is due to the hardness of our problem (which is NP-complete, as discussed in Corollary~\ref{col:np}), as the hypergraph partitioner does not manage to find the optimal partition of large/complex graphs. Nevertheless, enabling at least one of the extensions is always better than using none; and in our tests, enabling both extensions was always at least the second best option, so we propose it as the default configuration. Besides, discussing Figure~\ref{fig:results4} we concluded that not every quantum circuit is susceptible to being efficiently distributed, as in cases such as the Quantum Fourier Transform (QFT), the number of ebits required is larger than the number of qubits used in the actual computation. 

This thesis may be seen as the first few steps towards compilers that adapt quantum programs to be run in distributed architectures. The implementation of our algorithm -- although just a prototype -- was integrated within the Quipper system, a quantum programming language with its own compiler. Further work should be put into refining our implementation, so it is as efficient and scalable as it would be needed for practical use. 

Besides, what we achieve in this thesis is a fine-grained distribution of the circuit, in the sense that our algorithm decides where each qubit -- the smallest unit of information -- is allocated. However, we know from classical computer science that it is often better to have a coarse-grained distribution, where the user explicitly indicates blocks of operations that should be executed locally. Our approach could be easily extended to accommodate this idea, as described in the first point of the following section.

\section{Further work}
\label{FurtherWork}

In this section we suggest functionalities and other improvements that would be worthwhile working on in the future:

\begin{itemize}
  \item \textit{Coarse-grained distribution}: We may allow the user to assert that a group of qubits should be allocated to the same QPU. The user would use this functionality whenever the selected qubits had to interact intensively (e.g.\ a group of qubits participating on the circuit implementing an oracle). The user could convey this information using the comment command provided by Quipper (as if it were a compiler pragma). Our algorithm would read these comments and group the corresponding wires in a single vertex of the hypergraph, so they would always be allocated together. This would simplify the work of the hypergraph partitioner, potentially allowing it to find a better partition of the rest of the wires.
  \item \textit{CNOT interchange optimisation}: We discussed this problem in \S\ref{Interchange}, arguing it would be a natural extension to our algorithm. However, we were unable to find a procedure that guaranteed some degree of optimality. Still, there might be a subtle strategy to do so, involving dynamic programming. If no strategy can be found, we could still implement the different approaches we propose at the end of section \S\ref{Interchange}, then test which combination of them yields the best results.
  \item \textit{Choice of parameters}: Apart from \(k\) -- the number of QPUs we wish to distribute across -- there is an extra parameter, \(\varepsilon\) (load-imbalance tolerance), whose impact we have not tested. Additionally, we may have some extra parameters to fix depending on how we decide to control communication bottlenecks (see \S\ref{Bottleneck}) or how we choose to manage the CNOT interchange problem (see \S\ref{Interchange}). We should test different configurations of these parameters and decide on a default value for them. Besides, if we studied the effect of each parameter in detail, we may be able to come up with a decision algorithm that chooses the appropriate values to use depending on some characteristics of the input.
  %In the discussion of Figures~\ref{fig:results3} and~\ref{fig:results4}, we argued there seemed to be a `sweet-spot' value for the parameter \(k\) (i.e.\ the number of QPUs we distribute across), which was different for each circuit. 
  \item \textit{Non-uniform partition}: Throughout the thesis we assumed that the user would wish to distribute the circuit across multiple identical QPUs. However, it may happen that the QPUs available to the user have different numbers of qubits. Our algorithm can be easily adapted to manage this problem by asking the hypergraph partitioner to split the hypergraph into non-uniform blocks (i.e.\ with different number of vertices, decided beforehand). \texttt{KaHyPart}, the hypergraph partitioner we use, does give this option, so adding this functionality is straight-forward.
  \item \textit{Refined implementation}: As we discussed in \S\ref{implementation}, our implementation makes use of a simple list data structure, which is the main cause of inefficiencies in our code. Quipper has an internal data structure meant to manage circuits in an efficient and scalable manner. We should adapt our implementation to make use of their data structure, which should improve efficiency considerably.

\end{itemize}
